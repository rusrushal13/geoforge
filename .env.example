# GeoForge Configuration
# Copy this file to .env and fill in your API keys

# =============================================================================
# LLM Provider API Keys (optional - Ollama works without any keys!)
# =============================================================================

# Google Gemini (optional)
GEMINI_API_KEY=

# OpenAI (optional)
OPENAI_API_KEY=

# Anthropic Claude (optional)
ANTHROPIC_API_KEY=

# =============================================================================
# Default Settings
# =============================================================================

# Default LLM provider: ollama (default), gemini, openai, anthropic
# Ollama is the default because it's free and works offline!
DEFAULT_LLM_PROVIDER=ollama

# Default model per provider (free tier compatible - January 2026)
GEMINI_MODEL=gemini-2.5-flash
OPENAI_MODEL=gpt-5.2
ANTHROPIC_MODEL=claude-sonnet-4-5
OLLAMA_MODEL=qwen3-coder-next

# =============================================================================
# Reproducibility Settings
# =============================================================================

# Temperature: 0.0 = deterministic, 1.0 = creative (default: 0.0)
LLM_TEMPERATURE=0.0

# Random seed for reproducible outputs (default: 42)
LLM_SEED=42

# =============================================================================
# Ollama Settings (for local models)
# =============================================================================

# Ollama server URL (default: http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# Model will be auto-downloaded if not present!

# =============================================================================
# Output Settings
# =============================================================================

# Default output directory for generated files
OUTPUT_DIR=examples/outputs
